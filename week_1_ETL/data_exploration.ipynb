{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68bac8d0",
   "metadata": {},
   "source": [
    "# Exploring Museum Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c806e3f",
   "metadata": {},
   "source": [
    "**Enter Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ccce298",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from os import environ as ENV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33dfffd",
   "metadata": {},
   "source": [
    "Create a connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ca992f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    dbname=ENV['DB_NAME'],\n",
    "        user=ENV['DB_USER'],\n",
    "        password=ENV['DB_PASSWORD'],\n",
    "        host=ENV['DB_HOST'],\n",
    "        port=ENV['DB_PORT'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d93c382",
   "metadata": {},
   "source": [
    "### Highest Average Rating Per Exhibit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "397c3174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           exhibition_name          avg_rating\n",
      "0  The Crenshaw Collection  2.8305084745762712\n",
      "1       Measureless to Man  1.9294117647058824\n",
      "2       Our Polluted World  1.9169435215946844\n",
      "3               Adaptation  1.4259740259740260\n",
      "4      Cetacean Sensations  1.2162162162162162\n"
     ]
    }
   ],
   "source": [
    "cur = conn.cursor()\n",
    "result = cur.execute(\"\"\"SELECT exhibition_name, avg(rating_id) avg_rating\n",
    "                        FROM exhibition\n",
    "                        JOIN review USING(exhibition_id)\n",
    "                        GROUP BY exhibition_name\n",
    "                        ORDER BY avg_rating DESC;\"\"\")\n",
    "result = cur.fetchall()\n",
    "cur.close()\n",
    "\n",
    "df =  pd.DataFrame(result, columns=['exhibition_name', 'avg_rating'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b388f174",
   "metadata": {},
   "source": [
    "The exhibition with the best rating is The Crenshaw Collection. Significantly better than second. The worst rated was Cetacean Sensations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ddf18a5",
   "metadata": {},
   "source": [
    "### Look at total engagement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d196fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           exhibition_name  total_ratings\n",
      "0      Cetacean Sensations            481\n",
      "1  The Crenshaw Collection            472\n",
      "2       Measureless to Man            425\n",
      "3               Adaptation            385\n",
      "4       Our Polluted World            301\n"
     ]
    }
   ],
   "source": [
    "cur = conn.cursor()\n",
    "result = cur.execute(\"\"\"SELECT exhibition_name, COUNT(review_id) AS total_ratings\n",
    "                        FROM exhibition\n",
    "                        JOIN review USING(exhibition_id)\n",
    "                        GROUP BY exhibition_name\n",
    "                        ORDER BY total_ratings DESC;\"\"\")\n",
    "result = cur.fetchall()\n",
    "cur.close()\n",
    "\n",
    "df = pd.DataFrame(result, columns=['exhibition_name', 'total_ratings'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98eaaacf",
   "metadata": {},
   "source": [
    "While Cetacean Sensations was the lowest rating it caused the most engagement. Likely meaning people were disappointed enough to leave a review. Our Polluted World may have been forgettable and the viewer didn't want to leave feedback."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942d1073",
   "metadata": {},
   "source": [
    "### Look at the average rating per floor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "87d8b072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  floor_name          avg_rating\n",
      "0          2  2.8305084745762712\n",
      "1          3  1.9169435215946844\n",
      "2          1  1.5507726269315673\n",
      "3      Vault  1.4259740259740260\n"
     ]
    }
   ],
   "source": [
    "cur = conn.cursor()\n",
    "result = cur.execute(\"\"\"SELECT floor_name, avg(rating_id) AS avg_rating\n",
    "                        FROM floor_assignment\n",
    "                        JOIN exhibition USING(exhibition_id)\n",
    "                        JOIN floor USING(floor_id)\n",
    "                        JOIN review USING(exhibition_id)\n",
    "                        GROUP BY floor_name\n",
    "                        ORDER BY avg_rating DESC;\"\"\")\n",
    "result = cur.fetchall()\n",
    "cur.close()\n",
    "\n",
    "df = pd.DataFrame(result, columns=['floor_name', 'avg_rating'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03cd34d4",
   "metadata": {},
   "source": [
    "Perhaps the Vault meant it was a worse environment with less windows? Not enough exhibitions to read too much into the data here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
